"""
M√≥dulo de procesamiento de im√°genes para segmentaci√≥n de coples
Contiene funciones de preprocesamiento y postprocesamiento de im√°genes
"""

import cv2
import numpy as np
from config import InferenceConfig, VisualizationConfig


def preprocess_image_segmentation(image, input_size=None):
    """
    Preprocesa la imagen para el modelo de segmentaci√≥n de coples.
    Optimizado para resoluci√≥n 1024x1024
    
    Args:
        image (np.ndarray): Imagen original en formato RGB
        input_size (int, optional): Tama√±o de entrada del modelo
        
    Returns:
        tuple: (imagen_preprocesada, info_preprocesamiento)
    """
    if input_size is None:
        input_size = InferenceConfig.INPUT_SIZE
    
    try:
        # Redimensionar a resoluci√≥n del modelo (1024x1024)
        model_size = input_size
        image_resized = cv2.resize(image, (model_size, model_size), interpolation=cv2.INTER_AREA)
        
        # La imagen ya est√° en RGB desde la c√°mara
        # Normalizar pixel values to [0,1] de manera eficiente
        new_image = image_resized.astype(np.float32, copy=False) / 255.0
        
        # Cambiar dimensiones de HWC a CHW de manera eficiente
        new_image = np.transpose(new_image, (2, 0, 1))
        
        # Agregar batch dimension
        new_image = np.expand_dims(new_image, axis=0)
        
        return new_image, (1.0, 0, 0, model_size, model_size)
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error en preprocesamiento: {e}")
        # Retornar imagen de fallback
        model_size = input_size
        fallback = np.zeros((1, 3, model_size, model_size), dtype=np.float32)
        return fallback, (1.0, 0, 0, model_size, model_size)


def postprocess_segmentation(prediction, original_shape, preprocess_info):
    """
    Postprocesa la predicci√≥n de segmentaci√≥n.
    
    Args:
        prediction (np.ndarray): Predicci√≥n del modelo
        original_shape (tuple): Forma original de la imagen (H, W, C)
        preprocess_info (tuple): Informaci√≥n del preprocesamiento
        
    Returns:
        np.ndarray: M√°scara de segmentaci√≥n postprocesada
    """
    scale, top, left, nh, nw = preprocess_info
    h, w = original_shape[:2]
    
    # Obtener la predicci√≥n de segmentaci√≥n
    if len(prediction.shape) == 4:
        # Si es (1, C, H, W), tomar el primer batch
        seg_pred = prediction[0]
    elif len(prediction.shape) == 2:
        # Si es (1, 2) - clasificaci√≥n binaria, crear m√°scara simple
        # Para este caso, asumimos que es clasificaci√≥n de defecto/no defecto
        # Crear una m√°scara del tama√±o de la imagen original
        seg_pred = np.zeros((h, w), dtype=np.uint8)
        
        # Si la predicci√≥n indica defecto (probabilidad > 0.5), marcar toda la imagen
        if prediction[0][1] > 0.5:  # Probabilidad de defecto
            seg_pred = np.ones((h, w), dtype=np.uint8)
        
        return seg_pred
    else:
        seg_pred = prediction
    
    # Si hay m√∫ltiples canales, tomar el canal con mayor probabilidad
    if len(seg_pred.shape) > 2 and seg_pred.shape[0] > 1:
        seg_pred = np.argmax(seg_pred, axis=0)
    elif len(seg_pred.shape) == 2:
        seg_pred = (seg_pred > 0.5).astype(np.uint8)
    else:
        seg_pred = (seg_pred[0] > 0.5).astype(np.uint8)
    
    # Si la m√°scara tiene el tama√±o correcto, redimensionar
    if seg_pred.shape != (h, w):
        # Recortar al tama√±o original de la imagen procesada si es necesario
        if seg_pred.shape != (nh, nw):
            seg_pred = seg_pred[top:top+nh, left:left+nw]
        
        # Redimensionar al tama√±o original
        seg_pred = cv2.resize(seg_pred.astype(np.uint8), (w, h), interpolation=cv2.INTER_NEAREST)
    
    return seg_pred


def crear_mascara_eliptica(mascara, x_center, y_center, box_w, box_h, img_w, img_h):
    """
    Crea una m√°scara el√≠ptica ultra-optimizada para velocidad (fallback).
    
    Args:
        mascara (np.ndarray): M√°scara donde dibujar
        x_center, y_center (int): Centro de la elipse
        box_w, box_h (int): Dimensiones del bounding box
        img_w, img_h (int): Dimensiones de la imagen
    """
    try:
        # M√©todo ultra-r√°pido: usar cv2.ellipse directamente
        # Par√°metros de la elipse
        a = max(1, box_w // 2 - 2)  # Semi-eje mayor horizontal
        b = max(1, box_h // 2 - 2)  # Semi-eje mayor vertical
        
        # Crear elipse principal usando OpenCV (mucho m√°s r√°pido)
        cv2.ellipse(mascara, (x_center, y_center), (a, b), 0, 0, 360, 1, -1)
        
        # Agregar solo una variaci√≥n simple con probabilidad baja
        if np.random.random() > 0.7:  # 30% de probabilidad
            # Elipse ligeramente m√°s grande
            a_outer = int(a * 1.1)
            b_outer = int(b * 1.1)
            
            # Crear m√°scara temporal para el borde
            temp_mask = np.zeros_like(mascara)
            cv2.ellipse(temp_mask, (x_center, y_center), (a_outer, b_outer), 0, 0, 360, 1, -1)
            cv2.ellipse(temp_mask, (x_center, y_center), (a, b), 0, 0, 360, 0, -1)
            
            # Aplicar solo algunos p√≠xeles del borde
            borde_pixels = np.where(temp_mask == 1)
            if len(borde_pixels[0]) > 0:
                # Tomar solo el 30% de los p√≠xeles del borde
                np.random.seed(int(x_center + y_center) % 1000)
                indices = np.random.choice(len(borde_pixels[0]), size=len(borde_pixels[0]) // 3, replace=False)
                mascara[borde_pixels[0][indices], borde_pixels[1][indices]] = 1
        
    except Exception as e:
        # Si hay error, usar m√°scara rectangular simple
        x1 = max(0, x_center - box_w // 2)
        y1 = max(0, y_center - box_h // 2)
        x2 = min(img_w, x_center + box_w // 2)
        y2 = min(img_h, y_center + box_h // 2)
        mascara[y1:y2, x1:x2] = 1


def crear_mascara_real(detection, prototipos, cx, cy, w_norm, h_norm, img_w, img_h):
    """
    Crea una m√°scara REAL usando coeficientes y prototipos del modelo YOLOv11.
    
    Args:
        detection (np.ndarray): Array de detecci√≥n con coeficientes
        prototipos (np.ndarray): Tensor de prototipos [32, 256, 256]
        cx, cy, w_norm, h_norm (float): Coordenadas normalizadas del bounding box
        img_w, img_h (int): Dimensiones de la imagen original
        
    Returns:
        np.ndarray: M√°scara real o None si hay error
    """
    try:
        # Extraer los 32 coeficientes de m√°scara
        if len(detection) == 37:
            # Formato: [x,y,w,h,conf,coef1...coef32] (sin clase expl√≠cita)
            coeficientes = detection[5:37]  # 32 coeficientes
        elif len(detection) == 38:
            # Formato: [x,y,w,h,conf,class,coef1...coef32]
            coeficientes = detection[6:38]  # 32 coeficientes
        else:
            print(f"   ‚ö†Ô∏è Formato de detecci√≥n no esperado: {len(detection)} valores")
            return None
        
        # Verificar que tenemos exactamente 32 coeficientes
        if len(coeficientes) != 32:
            print(f"   ‚ö†Ô∏è Coeficientes incorrectos: {len(coeficientes)} (esperado: 32)")
            return None
        
        # Multiplicaci√≥n matricial: coeficientes @ prototipos
        # coeficientes: [32] @ protos: [32, 256, 256] -> [256, 256]
        mascara_cruda = np.dot(coeficientes, prototipos.reshape(32, -1)).reshape(256, 256)
        
        # Aplicar sigmoid para obtener probabilidades
        mascara_prob = 1 / (1 + np.exp(-mascara_cruda))
        
        # Aplicar umbral para obtener m√°scara binaria
        mascara_binaria = (mascara_prob > 0.5).astype(np.uint8)
        
        # Recortar m√°scara seg√∫n el bounding box de la detecci√≥n
        mask_size = 256
        
        # Calcular bounding box en coordenadas de la m√°scara
        x_center_mask = int(cx * mask_size)
        y_center_mask = int(cy * mask_size)
        box_w_mask = int(w_norm * mask_size)
        box_h_mask = int(h_norm * mask_size)
        
        # Calcular esquinas del bounding box en la m√°scara
        x1_mask = max(0, x_center_mask - box_w_mask // 2)
        y1_mask = max(0, y_center_mask - box_h_mask // 2)
        x2_mask = min(mask_size, x_center_mask + box_w_mask // 2)
        y2_mask = min(mask_size, y_center_mask + box_h_mask // 2)
        
        # Crear m√°scara recortada
        mascara_recortada = np.zeros((mask_size, mask_size), dtype=np.uint8)
        
        # Aplicar la m√°scara solo dentro del bounding box
        if x2_mask > x1_mask and y2_mask > y1_mask:
            region_mask = mascara_binaria[y1_mask:y2_mask, x1_mask:x2_mask]
            mascara_recortada[y1_mask:y2_mask, x1_mask:x2_mask] = region_mask
            
            # Estad√≠sticas de la m√°scara generada
            pixels_mascara = np.sum(region_mask)
            area_bbox = (x2_mask - x1_mask) * (y2_mask - y1_mask)
            cobertura = (pixels_mascara / area_bbox * 100) if area_bbox > 0 else 0
            
            print(f"     üéØ M√°scara real generada: {pixels_mascara} p√≠xeles ({cobertura:.1f}% del bbox)")
        else:
            print(f"     ‚ö†Ô∏è Bounding box inv√°lido en m√°scara: [{x1_mask},{y1_mask},{x2_mask},{y2_mask}]")
            return None
        
        # Redimensionar m√°scara de 256x256 a dimensiones originales
        mascara_final = cv2.resize(mascara_recortada, (img_w, img_h), interpolation=cv2.INTER_NEAREST)
        
        # Verificar que la m√°scara final tiene contenido
        if np.sum(mascara_final) == 0:
            print(f"     ‚ö†Ô∏è M√°scara final vac√≠a despu√©s de redimensionar")
            return None
        
        return mascara_final
        
    except Exception as e:
        print(f"   ‚ùå Error creando m√°scara real: {e}")
        return None


def crear_imagen_coloreada(imagen_original, mascara, class_names):
    """
    Crea una imagen coloreada para visualizar la segmentaci√≥n YOLO.
    
    Args:
        imagen_original (np.ndarray): Imagen original
        mascara (np.ndarray): M√°scara de segmentaci√≥n
        class_names (list): Lista de nombres de clases
        
    Returns:
        np.ndarray: Imagen coloreada con visualizaci√≥n
    """
    if mascara is None:
        return imagen_original.copy()
    
    imagen_coloreada = imagen_original.copy()
    
    # Para segmentaci√≥n YOLO de coples (defecto/no defecto)
    if len(class_names) == 1:
        # Si hay defecto detectado (m√°scara == 1)
        if np.any(mascara == 1):
            # Aplicar color rojo semi-transparente para defectos
            color = VisualizationConfig.DEFECT_COLOR
            overlay = imagen_coloreada.copy()
            
            # Crear overlay con color rojo en las √°reas defectuosas
            overlay[mascara == 1] = color
            
            # Mezclar con transparencia
            imagen_coloreada = cv2.addWeighted(
                imagen_coloreada, 1 - VisualizationConfig.OVERLAY_ALPHA, 
                overlay, VisualizationConfig.OVERLAY_ALPHA, 0
            )
            
            # Agregar contornos m√∫ltiples para mejor visualizaci√≥n
            contours, _ = cv2.findContours(mascara, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # Contorno exterior amarillo grueso
            cv2.drawContours(imagen_coloreada, contours, -1, 
                           VisualizationConfig.CONTOUR_OUTER_COLOR, 
                           VisualizationConfig.CONTOUR_THICKNESS_OUTER)
            
            # Contorno interior blanco fino
            cv2.drawContours(imagen_coloreada, contours, -1, 
                           VisualizationConfig.CONTOUR_INNER_COLOR, 
                           VisualizationConfig.CONTOUR_THICKNESS_INNER)
            
            # Marcar centros de detecci√≥n
            for contour in contours:
                if cv2.contourArea(contour) > VisualizationConfig.MIN_CONTOUR_AREA:
                    M = cv2.moments(contour)
                    if M["m00"] != 0:
                        cx = int(M["m10"] / M["m00"])
                        cy = int(M["m01"] / M["m00"])
                        cv2.circle(imagen_coloreada, (cx, cy), 
                                 VisualizationConfig.CENTER_POINT_RADIUS, 
                                 VisualizationConfig.CENTER_POINT_COLOR, -1)
    else:
        # Para m√∫ltiples clases
        from utils import create_colormap
        colormap = create_colormap(len(class_names))
        
        for class_id in range(1, len(class_names) + 1):
            # Crear m√°scara para esta clase
            class_mask = (mascara == class_id).astype(np.uint8)
            
            if np.any(class_mask):
                # Aplicar color con transparencia
                color = colormap[class_id - 1] if class_id - 1 < len(colormap) else (255, 0, 0)
                overlay = imagen_coloreada.copy()
                overlay[class_mask == 1] = color
                
                # Mezclar con transparencia
                imagen_coloreada = cv2.addWeighted(
                    imagen_coloreada, 1 - VisualizationConfig.OVERLAY_ALPHA, 
                    overlay, VisualizationConfig.OVERLAY_ALPHA, 0
                )
                
                # Agregar contornos m√∫ltiples
                contours, _ = cv2.findContours(class_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                # Contorno exterior amarillo grueso
                cv2.drawContours(imagen_coloreada, contours, -1, 
                               VisualizationConfig.CONTOUR_OUTER_COLOR, 
                               VisualizationConfig.CONTOUR_THICKNESS_OUTER)
                
                # Contorno interior blanco fino
                cv2.drawContours(imagen_coloreada, contours, -1, 
                               VisualizationConfig.CONTOUR_INNER_COLOR, 
                               VisualizationConfig.CONTOUR_THICKNESS_INNER)
                
                # Marcar centros de detecci√≥n
                for contour in contours:
                    if cv2.contourArea(contour) > VisualizationConfig.MIN_CONTOUR_AREA:
                        M = cv2.moments(contour)
                        if M["m00"] != 0:
                            cx = int(M["m10"] / M["m00"])
                            cy = int(M["m01"] / M["m00"])
                            cv2.circle(imagen_coloreada, (cx, cy), 
                                     VisualizationConfig.CENTER_POINT_RADIUS, 
                                     VisualizationConfig.CENTER_POINT_COLOR, -1)
    
    return imagen_coloreada


def agregar_anotaciones_imagen(imagen, mascara, class_names, tiempo_captura, tiempo_inferencia, tiempo_total, usar_mascaras_elipticas):
    """
    Agrega anotaciones de texto a la imagen con informaci√≥n de segmentaci√≥n.
    
    Args:
        imagen (np.ndarray): Imagen base
        mascara (np.ndarray): M√°scara de segmentaci√≥n
        class_names (list): Lista de nombres de clases
        tiempo_captura (float): Tiempo de captura en ms
        tiempo_inferencia (float): Tiempo de inferencia en ms
        tiempo_total (float): Tiempo total en ms
        usar_mascaras_elipticas (bool): Si se usan m√°scaras el√≠pticas
        
    Returns:
        np.ndarray: Imagen con anotaciones
    """
    frame_anotado = imagen.copy()
    
    # Informaci√≥n de segmentaci√≥n YOLO
    clases_detectadas = np.unique(mascara)
    if 1 in clases_detectadas:
        nombre_clase = class_names[0] if class_names else "Defecto"
        pixels_defecto = np.sum(mascara == 1)
        porcentaje = (pixels_defecto / mascara.size) * 100
        tipo_mascara = "El√≠ptica" if usar_mascaras_elipticas else "Rectangular"
        texto_principal = f"YOLO Seg ({tipo_mascara}) - Defecto: {pixels_defecto} pixeles ({porcentaje:.2f}%)"
    else:
        texto_principal = "YOLO Seg - Sin defectos segmentados"
    
    cv2.putText(frame_anotado, texto_principal, (10, 30), 
                VisualizationConfig.FONT, VisualizationConfig.FONT_SCALE, 
                VisualizationConfig.TEXT_COLOR, VisualizationConfig.FONT_THICKNESS)
    
    # Tiempos
    texto_tiempos = f"Cap: {tiempo_captura:.1f}ms | Seg: {tiempo_inferencia:.1f}ms | Tot: {tiempo_total:.1f}ms"
    cv2.putText(frame_anotado, texto_tiempos, (10, 60), 
                VisualizationConfig.FONT, VisualizationConfig.SMALL_FONT_SCALE, 
                VisualizationConfig.TIME_TEXT_COLOR, VisualizationConfig.SMALL_FONT_THICKNESS)
    
    return frame_anotado 